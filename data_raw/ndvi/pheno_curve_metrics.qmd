---
title: "fitting and extracting phenological metrics"
format: html
editor: visual
---

```{r}

library(tidyverse)
library(phenofit)
library(oce)
library(zoo)
library(furrr)
library(progressr)

```

## Summary

This code extracts phenology metrics from NDVI time series for 100 randomly sampled trees:

1.  **Input**: Raw NDVI extractions by tree and date
2.  **Processing**:
    -   Despikes and detrends NDVI time series
    -   Fits Elmore curves with wHANTS smoothing
    -   Extracts phenology dates and metrics
3.  **Quality Filtering**: Keeps only trees with ≥6 seasons and mean R² ≥0.9
4.  **Output**: Phenology metrics with dates, DOY, fit statistics, and fit objects

The result is a high-quality dataset ready for phenology analysis and visualization.

# improved prcessing time uing list and panning

```{r, warning=FALSE}

# Load raw NDVI extraction data
read_rds("./raw_extracts/extracted_ndvi_value.rds") -> extracts

```

```{r}

batch_size <- 20
output_dir <- "./pheno_curve_metrics/batches"
dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)

# Get all trees
extracts %>% 
  group_by(UID) %>% 
  summarise(n = n()) %>% 
  sample_n(200) %>%
  pull(UID) -> all_trees

# Split into batches
total_trees <- length(all_trees)
n_batches <- ceiling(total_trees / batch_size)
tree_batches <- split(all_trees, ceiling(seq_along(all_trees) / batch_size))

message(sprintf("Processing %d trees in %d batches of ~%d", 
                total_trees, n_batches, batch_size))

# Function to process one tree (unchanged from your original)
process_tree <- function(tree_data, trees, total_trees, p = NULL) {
  
  if (!is.null(p)) p()  
  
  i <- unique(tree_data$UID)
  
  counter <- which(trees == i)
  
  if (counter %% 100 == 0) {
    message(sprintf("Progress: %d/%d (%.1f%%)", 
                    counter, total_trees, (counter/total_trees)*100))
  }
  
  tryCatch({
    
    # Preprocess NDVI
    tree_data %>% 
      mutate(ndvi = despike(ndvi, "median", n = 3, k = 5)) %>%
      mutate(
        time_numeric = as.numeric(im_date),
        trend = predict(lm(ndvi ~ time_numeric)),
        ndvi_detrended = ndvi - trend + mean(ndvi, na.rm = TRUE)
      ) -> extracts_samp
    
    # Prepare inputs
    test_input <- check_input(
      t = extracts_samp$im_date,
      y = extracts_samp$ndvi, 
      south = FALSE
    )
    
    x_detrended <- check_input(
      t = extracts_samp$im_date, 
      y = extracts_samp$ndvi_detrended,
      south = FALSE
    )
    
    # Detect growing seasons
    brks_mov <- season_mov(
      x_detrended,
      options = list(rFUN = "smooth_wWHIT")
    )
    
    # Fit phenology curves
    fit <- curvefits(test_input, brks_mov)
    stats <- get_GOF(fit)
    
    # Check fit quality
    fit_check <- stats %>% 
      filter(meth == "Elmore") %>% 
      mutate(UID = i) %>%
      group_by(UID) %>% 
      summarise(
        mean_r2 = mean(R2, na.rm = TRUE),  
        n = n()
      )
    
    if (fit_check$mean_r2 > 0.90 & fit_check$n >= 6) {
      
      # Extract phenology metrics
      metrics <- get_pheno(fit, "Elmore")
      
      metrics_date <- metrics$date$Elmore %>% 
        mutate(UID = i)
      
      metrics_doy <- metrics$doy$Elmore %>% 
        mutate(UID = i)
      
      # Create lookup tables
      fit_lookup <- data.frame(
        flag = names(fit),
        fit_data = I(fit))
      
      season_curve <- tibble(
        UID = i,
        season_data = list(test_input))
      
      # Join fit objects to statistics
      stats <- stats %>% 
        mutate(UID = i) %>%
        left_join(season_curve, by = "UID") %>% 
        left_join(fit_lookup, by = "flag")
      
      # Return results
      return(list(
        metrics_date = metrics_date,
        metrics_doy = metrics_doy,
        stats = stats
      ))
      
    } else {
      return(NULL)
    }
    
  }, error = function(e) {
    return(NULL)
  })
}

# Process each batch
for (batch_num in seq_along(tree_batches)) {
  
  message(sprintf("\n=== BATCH %d/%d ===", batch_num, n_batches))
  
  # Check if already processed
  batch_file <- file.path(output_dir, sprintf("batch_%03d.rds", batch_num))
  if (file.exists(batch_file)) {
    message("Batch already exists, skipping...")
    next
  }
  
  # Get trees for this batch
  trees <- tree_batches[[batch_num]]
  total_trees <- length(trees)
  
  # Pre-split data by tree
  extracts %>% 
    filter(UID %in% trees) %>% 
    select(UID, im_date, ndvi) %>% 
    group_split(UID, .keep = TRUE) -> extracts_split
  
  # Set up parallel processing
  plan(multisession, workers = availableCores() - 1)
  
  # Process all trees in parallel with progress bar
  with_progress({
    p <- progressor(steps = length(extracts_split))
    
    results <- future_map(
      extracts_split, 
      ~process_tree(.x, trees, total_trees, p),
      .options = furrr_options(seed = TRUE)
    )
  })
  
  # Combine results (remove NULLs from skipped trees)
  results <- compact(results)
  
  if (length(results) == 0) {
    message("No valid results in this batch, skipping save...")
    next
  }
  
  pheno_metrix_date <- map_df(results, "metrics_date")
  pheno_metrix_doy <- map_df(results, "metrics_doy")
  fit_stats <- map_df(results, "stats")
  
  # Join DOY and date phenology metrics
  left_join(
    pheno_metrix_doy, 
    pheno_metrix_date, 
    by = c("UID", "flag", "origin"),
    suffix = c("_doy", "_date")
  ) -> phen_metrix 
  
  # Join fit statistics with phenology metrics
  batch_results <- fit_stats %>% 
    filter(meth == "Elmore") %>%
    right_join(phen_metrix)
  
  # Save batch
  write_rds(batch_results, batch_file)
  message(sprintf("Saved batch %d with %d obs.", batch_num, nrow(batch_results)))
  
  # Clean up memory
  rm(extracts_split, results, pheno_metrix_date, pheno_metrix_doy, 
     fit_stats, phen_metrix, batch_results)
  gc()
}

# Combine all batches
message("\n=== Combining all batches ===")

batch_files <- list.files(output_dir, pattern = "^batch_.*\\.rds$", full.names = TRUE)

if (length(batch_files) == 0) {
  stop("No batch files found!")
}

all_results <- map_df(batch_files, read_rds)

# Save final combined output
write_rds(all_results, "./pheno_curve_metrics/extracted_metrics_test.rds")

message(sprintf("Done! Final dataset has %d rows from %d batches", 
                nrow(all_results), length(batch_files)))

```

```{r}

read_rds("./pheno_curve_metrics/extracted_metrics.rds") -> test_data

test_data

source("../../R/plot_year.R")

plot_year(test_data, "2022_1", "14063", metrics = "Inflection")

```

```{r}

plot_year(phen_metrix, "2018_1", "20788", metrics = "Derivative")

```
